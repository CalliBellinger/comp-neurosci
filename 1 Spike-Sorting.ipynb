{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Spike-Sorting\n",
    "\n",
    "The goal of this assignment is for you to learn how extracellular neural recordings are analyzed. You will be looking at recordings obtained from the songbird auditory cortex while recordings of bird songs were played to the animals.\n",
    "\n",
    "![experiment diagram](images/experiment_diagram.png \"Auditory Neurophysiology Experiment\")\n",
    "\n",
    "This web page is a Python notebook. It's a interactive document that lets you mix text and computer code, organized into `cells`. A cell can contain either text or code. This is a text cell. You can edit the contents of this cell by double-clicking, then save by typing `Ctrl-Enter`.\n",
    "\n",
    "Some of the cells are left blank or have placeholder text (in *italics*). *Your assignment is to complete those cells*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python comments are marked by `#`\n",
    "\n",
    "# These lines of code import some external libraries we'll use in this exercise:\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.aspect'] = 'auto'\n",
    "mpl.rcParams['image.cmap'] = 'jet'\n",
    "mpl.rcParams['figure.figsize'] = (15.0, 4.0)\n",
    "\n",
    "# This is a Python string literal. It will evaluate to itself.\n",
    "\"Hello world\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the menus and buttons above. You can cut and paste cells with the `Edit` menu to move them around. You can execute one or more cells using the `Cell` menu. The Python interpreter is called a `kernel`. Under the `Kernel` menu, you can restart or interrupt the interpreter if it gets stuck. The `Help` menu explains more about using the notebook and has links to some of the main scientific programming libraries.\n",
    "\n",
    "If you're completely new to programming or to Python, you should go through the following exercises from [Software Carpentry](https://software-carpentry.org/). This should take you about 60-90 minutes. You can create new notebooks under `File/New Notebook` to work through them, or you can insert cells here.\n",
    "\n",
    "- [Running and Quitting Python](http://swcarpentry.github.io/python-novice-gapminder/01-run-quit/)\n",
    "- [Variables](http://swcarpentry.github.io/python-novice-gapminder/02-variables/)\n",
    "- [Data Types](http://swcarpentry.github.io/python-novice-gapminder/03-types-conversion/)\n",
    "- [Functions](http://swcarpentry.github.io/python-novice-gapminder/04-built-in/)\n",
    "- [Lists](http://swcarpentry.github.io/python-novice-gapminder/11-lists/)\n",
    "- [Loops](http://swcarpentry.github.io/python-novice-gapminder/12-for-loops/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Working with Time Series and Point Process Data\n",
    "\n",
    "In neuroscience, much of the data we'll be working with represents some process that changes in time. There are two fundamental ways of representing time-varying data in a computer:\n",
    "\n",
    "- A **time series** is a quantitative physical property of a system measured over a time interval. In digital computers, time series data are always sampled at discrete moments in time, usually at fixed intervals. The *sampling rate* of the data is the number of times per second the underlying process was measured. Examples of time series include sound waveforms and recordings of extracellular voltage.\n",
    "\n",
    "- A **point process** is a series of times when an event took place. An example of a point process is the set of times when a neuron produced an action potential (spike).\n",
    "\n",
    "Both point processes and time series are represented in Python in data structures called an `arrays`. For a time series, the array holds the sequence of measurements. For a point process, the array holds the sequence of event times. We'll use a library called [numpy](http://www.numpy.org/) to store and manipulate arrays. Note that in the first code cell above, we imported the numpy library and gave it the alias `np`, so all the calls to numpy functions will be preceded by `np.`\n",
    "\n",
    "Here's an example of creating an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1.0, 1.2, 0.8, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with lists, we can access specific elements or ranges of elements using indices. Note that Python uses zero-based indexing, which means that the index of the first element is 0, not 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last example used [slice notation](https://www.pythoncentral.io/how-to-slice-listsarrays-and-tuples-in-python/) to request the first two elements of the array. Slices are a powerful feature when working with arrays and other collections.\n",
    "\n",
    "You can do math operations on every element of the array with a single function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a scalar to an array, or add two arrays of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "56 + arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr + (2 * arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Working with Acoustic Stimuli\n",
    "\n",
    "Sound consists of waves of pressure moving through the air or another medium. When these waves press against the eardrum, the bones (or bone, if you're a bird) in the middle ear transmit the wave to the fluid in the cochlea. Movements in this fluid are detected by hair cells, which transduce the sound into neural signals. Sound is recorded with a microphone, which transduces pressure changes into electrical voltage changes. These in turn can be sampled by a digitizer and turned into an array of numbers. Although the sound wave is traveling through space, your eardrum or a microphone sits at a specific location and responds to changes in the pressure. Look at the animation below and imagine what you would measure over time at the location of the rightmost red dot.\n",
    "\n",
    "![acoustic wave](images/Planewave1.gif \"Traveling Pressure Wave\")\n",
    "\n",
    "Sound recordings can be stored in a variety of file formats. One of the most common is the `wave` format, which is what we'll be using here. The stimulus files used in this experiment have been placed in the `stimuli` directory. We can use the `os` module in Python to get a list of the contents of this directory:<a id=\"stim_list\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('stimuli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, `motifs.csv` is not a sound file. We're going to use it in a later activity. Let's listen to `A8.wav`. If you prefer, you can download the file using [this link](stimuli/A8.wav) and open it in a sound-processing program like [Audacity](http://www.audacityteam.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = \"A8\"\n",
    "stimfile = os.path.join(\"stimuli\", stim) + \".wav\"\n",
    "IPython.display.Audio(stimfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use a python package called `ewave` to load the file. The `ewave.open` function returns an object that we can use to access the data. We'll assign this object to the variable `wavfile`. An important quantity to note is the **sampling rate**, which indicates how frequently the sound pressure wave was measured during the recording. The units are samples per second, or *Hz*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ewave\n",
    "wavfile = ewave.open(stimfile)\n",
    "wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then read the contents of the file into an array using the `read` method. *Methods* are functions that have been associated with an object, and they're called like this. You can see that the `read` method returned an array of 16-bit integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osc = wavfile.read(memmap=False)\n",
    "osc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `...` means Python is omitting the samples in the middle, so we don't know how long the array is. To get the number of samples in the array, we use the builtin `len` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(osc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: The cell below contains incomplete code. To receive credit for this question, edit the code so it produces the correct answer (9.28 seconds) without raising any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write code here to calculate the variable used in the statement below\n",
    "stim_length = \n",
    "print(\"The stimulus is %3.2f seconds long\" % stim_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing time series\n",
    "\n",
    "We can't learn much about the sound just by looking at the numbers in the array. We need to plot it out using the matplotlib library. We've imported matplotlib into the variable `plt`, and we'll use the most basic plotting function, `plot`. Remember that you can get a list of functions in `plt` by typing `plt.` and then hitting the `Tab` key. You can also get help about a specific function by typing `Shift-Tab` inside the parentheses of the function. Try putting your cursor on `osc` in the cell below and typing `Shift-Tab`. Click the up arrow to get the full documentation string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(osc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot this command generates by default is a line plot. Because there are so many data points in the array, what you see is a waveform that primarily represents the overall amplitude of the sound. The y-axis indicates the values in the array, which have arbitrary units. We only provided a single array to the `plot` function, so the x-axis indicates the number of samples.  To plot the signal as a function of time, we'll need to create a second array that holds the time at each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0.0, len(osc)) / wavfile.sampling_rate\n",
    "plt.plot(t, osc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: In the cell below, plot samples 1000-2000 of the waveform, as a function of time in *milliseconds*. Hint: you'll need to take advantage of some of the features of arrays discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: In the cell below, describe what the waveform looks like. How is it similar to the waveform in the animation above? How is it different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click this text and enter your response*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrograms\n",
    "\n",
    "Another way of visualizing a time series is as a spectrogram. The spectrogram is based on a mathematical operation called the [Fourier transform](https://en.wikipedia.org/wiki/Fourier_transform), which converts a signal from the *time domain* to the *frequency domain*. That is, instead of representing the sound pressure as a function of time, we will show how much the signal varies as a function of frequency.\n",
    "\n",
    "In a spectrogram, the original signal is divided up into short, overlapping windows. The signal in each window is converted to a frequency representation using the Fourier transform, and then the windows are \"stacked up\" to produce a two-dimensional image, with time on the x-axis and frequency on the y-axis.\n",
    "\n",
    "![spectrogram calculation](images/spectrogram_calculation.png)\n",
    "\n",
    "You can read a spectrogram a little bit like a musical score. The intensity of the image indicates how much power there is in the signal at a particular time and frequency. There are many different color schemes, but this is largely a matter of preference.\n",
    "\n",
    "Let's calculate the spectrogram of the signal we just loaded. Although matplotlib comes with a spectrogram function, we're going to use an external library called `libtfr`. The cell below demonstrates the use of a user-defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libtfr\n",
    "\n",
    "# this parameter controls the analysis window size\n",
    "NFFT = 256\n",
    "# this parameter controls the overlap\n",
    "shift = 128\n",
    "# this parameter controls the intensity scaling\n",
    "compress = 1\n",
    "\n",
    "def specgram(signal, nfft, shift, sampling_rate, compress):\n",
    "    # generate a transform object\n",
    "    D = libtfr.mfft_dpss(nfft, 3, 5, nfft)\n",
    "    # calculate the power spectrogram\n",
    "    P = D.mtspec(signal, shift)    \n",
    "    freq, find = libtfr.fgrid(sampling_rate, nfft)\n",
    "    bins = libtfr.tgrid(P, sampling_rate, shift)\n",
    "    return (np.log10(P + compress) - np.log10(compress), freq, bins)\n",
    "\n",
    "P, freq, bins = specgram(osc, NFFT, shift, wavfile.sampling_rate, compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the spectrogram, we'll need to use the `plt.imshow` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(P, extent=(bins[0], bins[-1], freq[0], freq[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a lot more interesting, doesn't it? Try listening to the sound while following along the spectrogram from right to left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('stimuli/A0.wav') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of parameters that can be tweaked to make this look as good as possible. In the cell below, adjust the values for NFFT, shift, and compress and then run the cell to see what the plot looks like and how it compares to the one above. If you want, you can zoom into a smaller interval by using slice notation on the `osc` array when you pass it to `specgram()`\n",
    "\n",
    "**Question 4**: Once you've got a sense of what each parameter controls, pick values that allow you to to see good detail in the plot. You should be able to see clear vertical, horizontal, and curving lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NFFT, shift and compress with different values\n",
    "P, freq, bins = specgram(osc, NFFT, shift, wavfile.sampling_rate, compress)\n",
    "plt.imshow(P, extent=(bins[0], bins[-1], freq[0], freq[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: In the cell below, describe how changing `NFFT`, `shift`, and `compress` change the appearance of the plot. How are frequency and time resolution related to the window size (NFFT)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click this text and enter your response*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Working with Spike Data\n",
    "\n",
    "The basic structure of an auditory neurophysiology experiment is that we play a stimulus to the animal while recording from one or more neurons (or *units*) in the brain. The neurons are usually presented with a range of different stimuli to probe how selective they are or determine what parts of the stimulus excite them the best.\n",
    "\n",
    "There are many sources of variability in the brain, so not every spike in a given trial is necessarily caused by the stimulus. Thus, each stimulus is usually presented 5-20 times to get an average that represents the part of the response that's driven by the stimulus. \n",
    "\n",
    "A key first step in analyzing the results of an experiment is to *sort spikes*. This is a process that takes the raw neural recordings, which are densely sampled time series, and extracts the times when a spike ocurred. To be able to say that a set of spikes represents a single neuron, we need to make sure that the waveforms are distinct from the noise. There are many different methods of doing *spike sorting*, but the end goal is the same: to produce a **point process** representation of the neural response.\n",
    "\n",
    "![spike sorting diagram](images/spike_sorting_diagram.png)\n",
    "\n",
    "Let's look at some spike data that's already been sorted. We'll be using a format for spike time data called [pprox](https://meliza.org/spec:2/pprox/), which is an extension of the widely adopted JSON format. A large collection of responses from about 240 neurons in the starling auditory cortex are stored under `data/spikes`. This directory is too large to list, so we'll just look at one file. The `tools` module contains some functions for working with `pprox` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import pprox\n",
    "unit = \"st49_2_1_5\"\n",
    "resp = pprox.load(unit)\n",
    "# select only the responses to A8\n",
    "resp_A8 = pprox.select_stimulus(resp, stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, point process data is also stored in arrays. However, rather than holding values that represent physical measurements, the values indicate the times when an event ocurred. Rather than indicate the absolute time when an event occurred, the values in the data we just loaded represent the event times relative to the start of the stimulus. Each trial is then stored in a Python container called a `list`. Lists are like arrays in how they use indexing, but are more flexible in what they can store. Let's look at the first trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_A8[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the times are negative; these correspond to spikes that occurred during a silent interval before the stimulus was played. These are sometimes referred to as \"spontaneous\" spikes, in contrast to the spikes that are driven by the stimulus.\n",
    "\n",
    "**Question 6**: Complete the code cell so that the printed statements are correct and do not produce any errors. You will need to use a [for loop](http://swcarpentry.github.io/python-novice-gapminder/12-for-loops/) (or a list comprehension, if you know what you're doing) to produce an aggregate count of spikes across trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here to calculate the variables used in the statements below\n",
    "print(\"The number of trials is %d\" % n_trials)\n",
    "print(\"The number of spikes in trial 2 is %d\" % n_events_trial_2)\n",
    "print(\"The average number of spikes in all the trials is %3.2f\" % avg_event_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing point process data\n",
    "\n",
    "If we try to plot one of the trials using the same command we used for time series data, the plot doesn't make a lot of sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resp_A8[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better representation of point process data is a **raster** plot, where the position on the x-axis represents the time when the event took place. We can make a simple raster plot with the vlines command. Take a look at the help for vlines (put the cursor inside the parentheses and type `Shift-Tab`) to see if you can understand why the command produces this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(resp_A8[0], 0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that there are some periods when the neuron is spiking very rapidly and some periods when it is not spiking at all. How do we know this isn't random, spontaneous activity? Let's see what the cell did on subsequent presentations of the same stimulus. We can use a for loop to produce a raster for each trial. Do you understand why the variable `i` is incremented in each loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for trial in resp_A8:\n",
    "    plt.vlines(trial, i, i + 0.5)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**: Describe differences and similarities in how the cell responds during the silent period (t < 0) and during the period when the stimulus is being presented. What do you think is happening during the gap between 2.2 and 4.5 seconds? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click this text and enter your response*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting multiple processes on the same time scale\n",
    "\n",
    "To get a better sense of how the cell is responding to the stimulus, we'd like to be see them next to each other on the same scale. Matplotlib can accomodate this using *subplots*. Subplots divide the figure into multiple frames. The following code brings together several concepts from above. As before, use the notebook's help and self-documentation features to understand how this next cell works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot for the spectrogram. Assumes you've created a spectrogram above.\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.imshow(P, extent=(bins[0], bins[-1], freq[0], freq[-1]))\n",
    "# create a subplot for the raster\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "for i, trial in enumerate(resp_A8):\n",
    "    ax2.vlines(trial, i, i + 0.5)\n",
    "# adjust the limits of the x axis so that the spikes align with the spectrogram\n",
    "ax2.set_xlim(bins[0], bins[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**: Compare the stimulus and the response. Are there any features in the stimulus that seem to be correlated with the periods where the cell is firing intensely? Are those features present in the periods when the cell is not firing. In your own words, what kinds of sounds do you think are driving the cell? How could you test this hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click this text and enter your response*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Putting it together\n",
    "\n",
    "In this final section, your task is to plot the response of the \"st49_2_1_5\" neuron to all of the `wav` files in the `stimuli` directory (see [this cell](#stim_list) for the list). As in the plot above, each response needs to be plotted under the stimulus and synchronized to it. This may sound simple, but there are a few little hiccups. First, not every stimulus in the `stimuli` directory was presented to the neuron. Second, to get full credit, you may not copy and paste your code however many times it takes to go through all the stimuli. You will need to use for loops, functions, or both. In addition to the resources linked above, you can consult the Software Carpentry chapters on [Looping through Data Sets](http://swcarpentry.github.io/python-novice-gapminder/13-looping-data-sets/) and [Writing Functions](http://swcarpentry.github.io/python-novice-gapminder/14-writing-functions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this statement will give you a large canvas on which to put all your subplots\n",
    "mpl.rcParams['figure.figsize'] = (15.0, 20.0)\n",
    "# insert your code here. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp-neurosci",
   "language": "python",
   "name": "comp-neurosci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
